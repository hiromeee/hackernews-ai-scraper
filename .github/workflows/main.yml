name: Build and Deploy AI News Site

on:
  schedule:
    - cron: "0 */6 * * *" # 6時間ごと
  workflow_dispatch:

# 以前の権限設定に 'id-token: write' を追加（デプロイに必要）
permissions:
  contents: read      # チェックアウトのために 'read' が必要
  pages: write       # GitHub Pagesにデプロイするために必要
  id-token: write    # デプロイ認証のために必要

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    
    steps:
      # 1. リポジトリのコードをチェックアウト
      - name: Check out repository
        uses: actions/checkout@v4

      # 2. Python環境のセットアップ
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"
          cache: "pip"

      # 3. 必要なライブラリをインストール
      - name: Install dependencies
        run: pip install -r requirements.txt

      # 4. ニュース取得＆AI要約を実行
      # (ここで ai_news.json が生成される)
      - name: Run Scraper and AI Summary
        run: python scrape_hackernews.py
        env:
          # GitHub SecretsからAPIキーを環境変数として渡す
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}

      # 5. 静的サイト (HTML) を構築
      # (ここで dist/index.html が生成される)
      - name: Build Static Site
        run: python build_site.py

      # 6. デプロイ成果物 (HTML) をアップロード
      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          # build_site.py で指定した出力先ディレクトリ
          path: './dist' 

      # 7. GitHub Pagesにデプロイ
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4